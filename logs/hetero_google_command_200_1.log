2025-05-24 13:52:24,438 - INFO - Model saved to models/hetero_gnn_model.pth
Epoch 0, Loss: 2.5519375801086426, Accuracy: 10.00%
Epoch 10, Loss: 1.365383505821228, Accuracy: 49.38%
Epoch 20, Loss: 0.5763878226280212, Accuracy: 91.25%
Epoch 30, Loss: 0.17007970809936523, Accuracy: 98.75%
Epoch 40, Loss: 0.03987611457705498, Accuracy: 100.00%
Epoch 50, Loss: 0.012797070667147636, Accuracy: 100.00%
Epoch 60, Loss: 0.005923214368522167, Accuracy: 100.00%
Epoch 70, Loss: 0.0036481693387031555, Accuracy: 100.00%
Epoch 80, Loss: 0.002690595807507634, Accuracy: 100.00%
Epoch 90, Loss: 0.0021565270144492388, Accuracy: 100.00%
2025-05-24 13:52:36,815 - INFO - Model saved to models/hetero_gnn_edge_regressor.pth
Epoch 0, Loss: 32.0887, BCE Loss: 32.0887
Epoch 10, Loss: 37.5405, BCE Loss: 37.5405
Epoch 20, Loss: 21.1611, BCE Loss: 21.1611
Epoch 30, Loss: 19.9912, BCE Loss: 19.9912
Epoch 40, Loss: 17.8033, BCE Loss: 17.8033
Epoch 50, Loss: 16.9463, BCE Loss: 16.9463
Epoch 60, Loss: 16.6143, BCE Loss: 16.6143
Epoch 70, Loss: 16.2965, BCE Loss: 16.2965
Epoch 80, Loss: 16.2521, BCE Loss: 16.2521
Epoch 90, Loss: 16.2447, BCE Loss: 16.2447
Epoch 100, Loss: 16.2491, BCE Loss: 16.2491
Epoch 110, Loss: 16.2499, BCE Loss: 16.2499
Epoch 120, Loss: 16.2493, BCE Loss: 16.2493
Epoch 130, Loss: 16.2513, BCE Loss: 16.2513
Epoch 140, Loss: 16.2522, BCE Loss: 16.2522
Epoch 150, Loss: 16.2523, BCE Loss: 16.2523
Epoch 160, Loss: 16.2526, BCE Loss: 16.2526
Epoch 170, Loss: 16.2530, BCE Loss: 16.2530
Epoch 180, Loss: 16.2883, BCE Loss: 16.2883
Epoch 190, Loss: 16.2882, BCE Loss: 16.2882
Epoch 200, Loss: 16.2881, BCE Loss: 16.2881
Epoch 210, Loss: 16.2881, BCE Loss: 16.2881
Epoch 220, Loss: 16.2880, BCE Loss: 16.2880
Epoch 230, Loss: 16.2879, BCE Loss: 16.2879
Epoch 240, Loss: 16.2878, BCE Loss: 16.2878
Epoch 250, Loss: 16.2877, BCE Loss: 16.2877
Epoch 260, Loss: 16.2877, BCE Loss: 16.2877
Epoch 270, Loss: 16.2876, BCE Loss: 16.2876
Epoch 280, Loss: 16.2875, BCE Loss: 16.2875
Epoch 290, Loss: 16.2874, BCE Loss: 16.2874
Epoch 300, Loss: 16.2874, BCE Loss: 16.2874
Epoch 310, Loss: 16.2873, BCE Loss: 16.2873
Epoch 320, Loss: 16.2872, BCE Loss: 16.2872
Epoch 330, Loss: 16.2872, BCE Loss: 16.2872
Epoch 340, Loss: 16.2871, BCE Loss: 16.2871
Epoch 350, Loss: 16.2870, BCE Loss: 16.2870
Epoch 360, Loss: 16.2870, BCE Loss: 16.2870
Epoch 370, Loss: 16.2869, BCE Loss: 16.2869
Epoch 380, Loss: 16.2869, BCE Loss: 16.2869
Epoch 390, Loss: 16.2868, BCE Loss: 16.2868
Epoch 400, Loss: 16.2868, BCE Loss: 16.2868
Epoch 410, Loss: 16.2867, BCE Loss: 16.2867
Epoch 420, Loss: 16.2867, BCE Loss: 16.2867
Epoch 430, Loss: 16.2866, BCE Loss: 16.2866
Epoch 440, Loss: 16.2866, BCE Loss: 16.2866
Epoch 450, Loss: 16.2866, BCE Loss: 16.2866
Epoch 460, Loss: 16.2865, BCE Loss: 16.2865
Epoch 470, Loss: 16.2865, BCE Loss: 16.2865
Epoch 480, Loss: 16.2864, BCE Loss: 16.2864
Epoch 490, Loss: 16.2864, BCE Loss: 16.2864
2025-05-24 13:53:04,615 - INFO - Model saved to models/hetero_gnn_model.pth
Epoch 0, Loss: 2.429440498352051, Accuracy: 11.88%
Epoch 10, Loss: 1.428968906402588, Accuracy: 56.88%
Epoch 20, Loss: 0.6673834919929504, Accuracy: 85.62%
Epoch 30, Loss: 0.22880975902080536, Accuracy: 100.00%
Epoch 40, Loss: 0.0580262765288353, Accuracy: 100.00%
Epoch 50, Loss: 0.018999848514795303, Accuracy: 100.00%
Epoch 60, Loss: 0.00879211537539959, Accuracy: 100.00%
Epoch 70, Loss: 0.00542307598516345, Accuracy: 100.00%
Epoch 80, Loss: 0.003923005424439907, Accuracy: 100.00%
Epoch 90, Loss: 0.003106402000412345, Accuracy: 100.00%
2025-05-24 13:53:16,640 - INFO - Model saved to models/hetero_gnn_edge_regressor.pth
Epoch 0, Loss: 29.2713, BCE Loss: 29.2713
Epoch 10, Loss: 15.2689, BCE Loss: 15.2689
Epoch 20, Loss: 11.8964, BCE Loss: 11.8964
Epoch 30, Loss: 8.7164, BCE Loss: 8.7164
Epoch 40, Loss: 8.1711, BCE Loss: 8.1711
Epoch 50, Loss: 7.6983, BCE Loss: 7.6983
Epoch 60, Loss: 7.4968, BCE Loss: 7.4968
Epoch 70, Loss: 7.1713, BCE Loss: 7.1713
Epoch 80, Loss: 7.0469, BCE Loss: 7.0469
Epoch 90, Loss: 7.0382, BCE Loss: 7.0382
Epoch 100, Loss: 7.0343, BCE Loss: 7.0343
Epoch 110, Loss: 7.0347, BCE Loss: 7.0347
Epoch 120, Loss: 7.0347, BCE Loss: 7.0347
Epoch 130, Loss: 7.0347, BCE Loss: 7.0347
Epoch 140, Loss: 7.0349, BCE Loss: 7.0349
Epoch 150, Loss: 7.0351, BCE Loss: 7.0351
Epoch 160, Loss: 7.0352, BCE Loss: 7.0352
Epoch 170, Loss: 7.0354, BCE Loss: 7.0354
Epoch 180, Loss: 7.0356, BCE Loss: 7.0356
Epoch 190, Loss: 7.0358, BCE Loss: 7.0358
Epoch 200, Loss: 7.0360, BCE Loss: 7.0360
Epoch 210, Loss: 7.0361, BCE Loss: 7.0361
Epoch 220, Loss: 7.0362, BCE Loss: 7.0362
Epoch 230, Loss: 7.0364, BCE Loss: 7.0364
Epoch 240, Loss: 7.0365, BCE Loss: 7.0365
Epoch 250, Loss: 7.0366, BCE Loss: 7.0366
Epoch 260, Loss: 7.0367, BCE Loss: 7.0367
Epoch 270, Loss: 7.0368, BCE Loss: 7.0368
Epoch 280, Loss: 7.0369, BCE Loss: 7.0369
Epoch 290, Loss: 7.0370, BCE Loss: 7.0370
Epoch 300, Loss: 7.0370, BCE Loss: 7.0370
Epoch 310, Loss: 7.0371, BCE Loss: 7.0371
Epoch 320, Loss: 7.0372, BCE Loss: 7.0372
Epoch 330, Loss: 7.0372, BCE Loss: 7.0372
Epoch 340, Loss: 7.0373, BCE Loss: 7.0373
Epoch 350, Loss: 7.0373, BCE Loss: 7.0373
Epoch 360, Loss: 7.0374, BCE Loss: 7.0374
Epoch 370, Loss: 7.0374, BCE Loss: 7.0374
Epoch 380, Loss: 7.0375, BCE Loss: 7.0375
Epoch 390, Loss: 7.0375, BCE Loss: 7.0375
Epoch 400, Loss: 7.0375, BCE Loss: 7.0375
Epoch 410, Loss: 7.0376, BCE Loss: 7.0376
Epoch 420, Loss: 7.0376, BCE Loss: 7.0376
Epoch 430, Loss: 7.0379, BCE Loss: 7.0379
Epoch 440, Loss: 7.0380, BCE Loss: 7.0380
Epoch 450, Loss: 7.0382, BCE Loss: 7.0382
Epoch 460, Loss: 7.0383, BCE Loss: 7.0383
Epoch 470, Loss: 7.0384, BCE Loss: 7.0384
Epoch 480, Loss: 7.0385, BCE Loss: 7.0385
Epoch 490, Loss: 7.0386, BCE Loss: 7.0386
Traceback (most recent call last):
  File "/home/yannick/Documents/Acoustic_Linguistic_GNN/gnn_heto_model.py", line 1, in <module>
    import dgl
  File "/home/yannick/.local/lib/python3.10/site-packages/dgl/__init__.py", line 14, in <module>
    from .backend import backend_name, load_backend  # usort: skip
  File "/home/yannick/.local/lib/python3.10/site-packages/dgl/backend/__init__.py", line 122, in <module>
    load_backend(get_preferred_backend())
  File "/home/yannick/.local/lib/python3.10/site-packages/dgl/backend/__init__.py", line 37, in load_backend
    import torch
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/__init__.py", line 1854, in <module>
    from . import _meta_registrations
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/_meta_registrations.py", line 9, in <module>
    from torch._decomp import (
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/_decomp/__init__.py", line 244, in <module>
    import torch._refs
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/_refs/__init__.py", line 1112, in <module>
    def bitwise_or(a: TensorLikeType, b: TensorLikeType) -> TensorLikeType:
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/_refs/__init__.py", line 1043, in inner
    register_decomposition(aten_op)(_ref)
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/_decomp/__init__.py", line 185, in decomposition_decorator
    pytree.tree_map_(register, aten_op)
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/utils/_pytree.py", line 607, in tree_map_
    deque(map(func, flat_args), maxlen=0)  # consume and exhaust the iterable
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/_decomp/__init__.py", line 182, in register
    _add_op_to_registry(registry, op, fn)
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/_decomp/__init__.py", line 51, in _add_op_to_registry
    overloads.append(getattr(op, ol))
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/_ops.py", line 733, in __getattr__
    op_, op_dk_, tags = torch._C._get_operation_overload(
KeyboardInterrupt
2025-05-24 13:56:02,635 - INFO - Model saved to models/hetero_gnn_model.pth
Epoch 0, Loss: 2.1931309700012207, Accuracy: 12.50%
Epoch 10, Loss: 1.4157477617263794, Accuracy: 53.75%
Epoch 20, Loss: 0.565183162689209, Accuracy: 90.00%
Epoch 30, Loss: 0.1500186324119568, Accuracy: 99.38%
Epoch 40, Loss: 0.03542948514223099, Accuracy: 100.00%
Epoch 50, Loss: 0.012719295918941498, Accuracy: 100.00%
Epoch 60, Loss: 0.006420210003852844, Accuracy: 100.00%
Epoch 70, Loss: 0.004044695291668177, Accuracy: 100.00%
Epoch 80, Loss: 0.002921049017459154, Accuracy: 100.00%
Epoch 90, Loss: 0.0022939560003578663, Accuracy: 100.00%
2025-05-24 13:56:15,280 - INFO - Model saved to models/hetero_gnn_edge_regressor.pth
Epoch 0, Loss: 29.6347, BCE Loss: 29.6347
Epoch 10, Loss: 21.1943, BCE Loss: 21.1943
Epoch 20, Loss: 14.5761, BCE Loss: 14.5761
Epoch 30, Loss: 13.2426, BCE Loss: 13.2426
Epoch 40, Loss: 10.0387, BCE Loss: 10.0387
Epoch 50, Loss: 8.2168, BCE Loss: 8.2168
Epoch 60, Loss: 7.1384, BCE Loss: 7.1384
Epoch 70, Loss: 6.1773, BCE Loss: 6.1773
Epoch 80, Loss: 5.7651, BCE Loss: 5.7651
Epoch 90, Loss: 5.7148, BCE Loss: 5.7148
Epoch 100, Loss: 5.7016, BCE Loss: 5.7016
Epoch 110, Loss: 5.6954, BCE Loss: 5.6954
Epoch 120, Loss: 5.6903, BCE Loss: 5.6903
Epoch 130, Loss: 5.6865, BCE Loss: 5.6865
Epoch 140, Loss: 5.6840, BCE Loss: 5.6840
Epoch 150, Loss: 5.6820, BCE Loss: 5.6820
Epoch 160, Loss: 5.6805, BCE Loss: 5.6805
Epoch 170, Loss: 5.6794, BCE Loss: 5.6794
Epoch 180, Loss: 5.6784, BCE Loss: 5.6784
Epoch 190, Loss: 5.6774, BCE Loss: 5.6774
Epoch 200, Loss: 5.6765, BCE Loss: 5.6765
Epoch 210, Loss: 5.6758, BCE Loss: 5.6758
Epoch 220, Loss: 5.6751, BCE Loss: 5.6751
Epoch 230, Loss: 5.6744, BCE Loss: 5.6744
Epoch 240, Loss: 5.6738, BCE Loss: 5.6738
Epoch 250, Loss: 5.6732, BCE Loss: 5.6732
Epoch 260, Loss: 5.6726, BCE Loss: 5.6726
Epoch 270, Loss: 5.6721, BCE Loss: 5.6721
Epoch 280, Loss: 5.6716, BCE Loss: 5.6716
Epoch 290, Loss: 5.6712, BCE Loss: 5.6712
Epoch 300, Loss: 5.6707, BCE Loss: 5.6707
Epoch 310, Loss: 5.6703, BCE Loss: 5.6703
Epoch 320, Loss: 5.6699, BCE Loss: 5.6699
Epoch 330, Loss: 5.6695, BCE Loss: 5.6695
Epoch 340, Loss: 5.6691, BCE Loss: 5.6691
Epoch 350, Loss: 5.6687, BCE Loss: 5.6687
Epoch 360, Loss: 5.6683, BCE Loss: 5.6683
Epoch 370, Loss: 5.6680, BCE Loss: 5.6680
Epoch 380, Loss: 5.6676, BCE Loss: 5.6676
Epoch 390, Loss: 5.6673, BCE Loss: 5.6673
Epoch 400, Loss: 5.6670, BCE Loss: 5.6670
Epoch 410, Loss: 5.6667, BCE Loss: 5.6667
Epoch 420, Loss: 5.6664, BCE Loss: 5.6664
Epoch 430, Loss: 5.6661, BCE Loss: 5.6661
Epoch 440, Loss: 5.6658, BCE Loss: 5.6658
Epoch 450, Loss: 5.6655, BCE Loss: 5.6655
Epoch 460, Loss: 5.6652, BCE Loss: 5.6652
Epoch 470, Loss: 5.6649, BCE Loss: 5.6649
Epoch 480, Loss: 5.6647, BCE Loss: 5.6647
Epoch 490, Loss: 5.6644, BCE Loss: 5.6644
2025-05-24 13:56:43,809 - INFO - Model saved to models/hetero_gnn_model.pth
Epoch 0, Loss: 2.976635456085205, Accuracy: 10.62%
Epoch 10, Loss: 1.3269798755645752, Accuracy: 54.37%
Epoch 20, Loss: 0.5801571607589722, Accuracy: 90.62%
Epoch 30, Loss: 0.18623380362987518, Accuracy: 98.12%
Epoch 40, Loss: 0.05584670230746269, Accuracy: 100.00%
Epoch 50, Loss: 0.01982448250055313, Accuracy: 100.00%
Epoch 60, Loss: 0.008902833797037601, Accuracy: 100.00%
Epoch 70, Loss: 0.005184720270335674, Accuracy: 100.00%
Epoch 80, Loss: 0.0035967263393104076, Accuracy: 100.00%
Epoch 90, Loss: 0.0027851550839841366, Accuracy: 100.00%
2025-05-24 13:56:56,845 - INFO - Model saved to models/hetero_gnn_edge_regressor.pth
Epoch 0, Loss: 18.8919, BCE Loss: 18.8919
Epoch 10, Loss: 20.6724, BCE Loss: 20.6724
Epoch 20, Loss: 14.5007, BCE Loss: 14.5007
Epoch 30, Loss: 12.0555, BCE Loss: 12.0555
Epoch 40, Loss: 9.4478, BCE Loss: 9.4478
Epoch 50, Loss: 8.7177, BCE Loss: 8.7177
Epoch 60, Loss: 7.8370, BCE Loss: 7.8370
Epoch 70, Loss: 7.6121, BCE Loss: 7.6121
Epoch 80, Loss: 7.4370, BCE Loss: 7.4370
Epoch 90, Loss: 7.2880, BCE Loss: 7.2880
Epoch 100, Loss: 7.2360, BCE Loss: 7.2360
Epoch 110, Loss: 7.2138, BCE Loss: 7.2138
Epoch 120, Loss: 7.2070, BCE Loss: 7.2070
Epoch 130, Loss: 7.2036, BCE Loss: 7.2036
Epoch 140, Loss: 7.2032, BCE Loss: 7.2032
Epoch 150, Loss: 7.2050, BCE Loss: 7.2050
Epoch 160, Loss: 7.2066, BCE Loss: 7.2066
Epoch 170, Loss: 7.2073, BCE Loss: 7.2073
Epoch 180, Loss: 7.2078, BCE Loss: 7.2078
Epoch 190, Loss: 7.2083, BCE Loss: 7.2083
Epoch 200, Loss: 7.2087, BCE Loss: 7.2087
Epoch 210, Loss: 7.2091, BCE Loss: 7.2091
Epoch 220, Loss: 7.2096, BCE Loss: 7.2096
Epoch 230, Loss: 7.2102, BCE Loss: 7.2102
Epoch 240, Loss: 7.2107, BCE Loss: 7.2107
Epoch 250, Loss: 7.2112, BCE Loss: 7.2112
Epoch 260, Loss: 7.2116, BCE Loss: 7.2116
Epoch 270, Loss: 7.2121, BCE Loss: 7.2121
Epoch 280, Loss: 7.2126, BCE Loss: 7.2126
Epoch 290, Loss: 7.2130, BCE Loss: 7.2130
Epoch 300, Loss: 7.2135, BCE Loss: 7.2135
Epoch 310, Loss: 7.2139, BCE Loss: 7.2139
Epoch 320, Loss: 7.2143, BCE Loss: 7.2143
Epoch 330, Loss: 7.2147, BCE Loss: 7.2147
Epoch 340, Loss: 7.2151, BCE Loss: 7.2151
Epoch 350, Loss: 7.2155, BCE Loss: 7.2155
Epoch 360, Loss: 7.2159, BCE Loss: 7.2159
Epoch 370, Loss: 7.2162, BCE Loss: 7.2162
Epoch 380, Loss: 7.2166, BCE Loss: 7.2166
Epoch 390, Loss: 7.2169, BCE Loss: 7.2169
Epoch 400, Loss: 7.2173, BCE Loss: 7.2173
Epoch 410, Loss: 7.2176, BCE Loss: 7.2176
Epoch 420, Loss: 7.2179, BCE Loss: 7.2179
Epoch 430, Loss: 7.2182, BCE Loss: 7.2182
Epoch 440, Loss: 7.2185, BCE Loss: 7.2185
Epoch 450, Loss: 7.2188, BCE Loss: 7.2188
Epoch 460, Loss: 7.2191, BCE Loss: 7.2191
Epoch 470, Loss: 7.2194, BCE Loss: 7.2194
Epoch 480, Loss: 7.2197, BCE Loss: 7.2197
Epoch 490, Loss: 7.2199, BCE Loss: 7.2199
2025-05-24 13:57:44,427 - INFO - Model saved to models/hetero_gnn_model.pth
Epoch 0, Loss: 3.119086980819702, Accuracy: 9.38%
Epoch 10, Loss: 1.4204151630401611, Accuracy: 62.50%
Epoch 20, Loss: 0.6358299851417542, Accuracy: 93.75%
Epoch 30, Loss: 0.2995643615722656, Accuracy: 100.00%
Epoch 40, Loss: 0.20021231472492218, Accuracy: 100.00%
Epoch 50, Loss: 0.17359304428100586, Accuracy: 100.00%
Epoch 60, Loss: 0.16442546248435974, Accuracy: 100.00%
Epoch 70, Loss: 0.1601209193468094, Accuracy: 100.00%
Epoch 80, Loss: 0.15757004916667938, Accuracy: 100.00%
Epoch 90, Loss: 0.15572741627693176, Accuracy: 100.00%
Epoch 0, Loss: 41.0582, BCE Loss: 40.8733
Epoch 10, Loss: 32.7585, BCE Loss: 32.5851
Epoch 20, Loss: 29.0462, BCE Loss: 28.8763
Epoch 30, Loss: 19.0232, BCE Loss: 18.8575
Epoch 40, Loss: 14.8861, BCE Loss: 14.7206
Epoch 50, Loss: 12.3972, BCE Loss: 12.2336
Epoch 60, Loss: 10.7005, BCE Loss: 10.5388
Epoch 70, Loss: 10.0558, BCE Loss: 9.8958
Epoch 80, Loss: 8.8256, BCE Loss: 8.6678
Epoch 90, Loss: 8.6828, BCE Loss: 8.5267
Epoch 100, Loss: 8.3428, BCE Loss: 8.1887
Epoch 110, Loss: 8.3243, BCE Loss: 8.1710
Epoch 120, Loss: 8.3197, BCE Loss: 8.1675
Epoch 130, Loss: 8.3167, BCE Loss: 8.1656
Epoch 140, Loss: 8.3147, BCE Loss: 8.1647
Epoch 150, Loss: 8.3133, BCE Loss: 8.1642
Epoch 160, Loss: 8.3122, BCE Loss: 8.1638
Epoch 170, Loss: 8.3113, BCE Loss: 8.1635
Epoch 180, Loss: 8.3106, BCE Loss: 8.1632
Epoch 190, Loss: 8.3099, BCE Loss: 8.1630
Epoch 200, Loss: 8.3093, BCE Loss: 8.1628
Epoch 210, Loss: 8.3088, BCE Loss: 8.1626
Epoch 220, Loss: 8.3083, BCE Loss: 8.1624
Epoch 230, Loss: 8.3078, BCE Loss: 8.1623
Epoch 240, Loss: 8.3073, BCE Loss: 8.1622
Epoch 250, Loss: 8.3069, BCE Loss: 8.1620
Epoch 260, Loss: 8.3065, BCE Loss: 8.1619
Epoch 270, Loss: 8.3061, BCE Loss: 8.1618
Epoch 280, Loss: 8.3057, BCE Loss: 8.1617
Epoch 290, Loss: 8.3054, BCE Loss: 8.1617
Epoch 300, Loss: 8.3050, BCE Loss: 8.1616
Epoch 310, Loss: 8.3047, BCE Loss: 8.1615
Epoch 320, Loss: 8.3044, BCE Loss: 8.1614
Epoch 330, Loss: 8.3041, BCE Loss: 8.1614
Epoch 340, Loss: 8.3038, BCE Loss: 8.1613
Epoch 350, Loss: 8.3035, BCE Loss: 8.1612
Epoch 360, Loss: 8.3032, BCE Loss: 8.1612
Epoch 370, Loss: 8.3030, BCE Loss: 8.1611
Epoch 380, Loss: 8.3027, BCE Loss: 8.1611
Epoch 390, Loss: 8.3025, BCE Loss: 8.1611
Epoch 400, Loss: 8.3022, BCE Loss: 8.1610
Epoch 410, Loss: 8.3020, BCE Loss: 8.1610
Epoch 420, Loss: 8.3018, BCE Loss: 8.1609
Epoch 430, Loss: 8.3015, BCE Loss: 8.1609
Epoch 440, Loss: 8.3013, BCE Loss: 8.1609
Epoch 450, Loss: 8.3011, BCE Loss: 8.1608
Traceback (most recent call last):
  File "/home/yannick/Documents/Acoustic_Linguistic_GNN/gnn_heto_link_pred_model.py", line 208, in <module>
    main(args.input_folder, args.graph_file, int(args.epochs), float(args.lamb), args.dataset)
  File "/home/yannick/Documents/Acoustic_Linguistic_GNN/gnn_heto_link_pred_model.py", line 187, in main
    model = train_link_prediction(
  File "/home/yannick/Documents/Acoustic_Linguistic_GNN/gnn_heto_link_pred_model.py", line 76, in train_link_prediction
    loss.backward()
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/yannick/.local/lib/python3.10/site-packages/torch/autograd/function.py", line 277, in apply
    def apply(self, *args):
KeyboardInterrupt
2025-05-24 16:05:39,409 - INFO - Model saved to models/hetero_gnn_model.pth
Epoch 0, Loss: 2.328066110610962, Accuracy: 13.75%
Epoch 10, Loss: 1.6420888900756836, Accuracy: 38.75%
Epoch 20, Loss: 0.8013416528701782, Accuracy: 81.88%
Epoch 30, Loss: 0.2087622880935669, Accuracy: 98.12%
Epoch 40, Loss: 0.041182391345500946, Accuracy: 100.00%
Epoch 50, Loss: 0.010183134116232395, Accuracy: 100.00%
Epoch 60, Loss: 0.004239375703036785, Accuracy: 100.00%
Epoch 70, Loss: 0.00250759394839406, Accuracy: 100.00%
Epoch 80, Loss: 0.0017990029882639647, Accuracy: 100.00%
Epoch 90, Loss: 0.0014295019209384918, Accuracy: 100.00%
Epoch 100, Loss: 0.001201117062009871, Accuracy: 100.00%
Epoch 110, Loss: 0.0010389711242169142, Accuracy: 100.00%
Epoch 120, Loss: 0.0009139496833086014, Accuracy: 100.00%
Epoch 130, Loss: 0.0008132734219543636, Accuracy: 100.00%
Epoch 140, Loss: 0.0007298160344362259, Accuracy: 100.00%
Epoch 150, Loss: 0.0006603713845834136, Accuracy: 100.00%
Epoch 160, Loss: 0.0006010939832776785, Accuracy: 100.00%
Epoch 170, Loss: 0.0005499404505826533, Accuracy: 100.00%
Epoch 180, Loss: 0.0005052737542428076, Accuracy: 100.00%
Epoch 190, Loss: 0.0004658144316636026, Accuracy: 100.00%
2025-05-24 16:05:53,014 - INFO - Model saved to models/hetero_gnn_edge_regressor.pth
Epoch 0, Loss: 34.4733, BCE Loss: 34.4733
Epoch 10, Loss: 18.8343, BCE Loss: 18.8343
Epoch 20, Loss: 15.6711, BCE Loss: 15.6711
Epoch 30, Loss: 13.0647, BCE Loss: 13.0647
Epoch 40, Loss: 11.1877, BCE Loss: 11.1877
Epoch 50, Loss: 10.0991, BCE Loss: 10.0991
Epoch 60, Loss: 9.3298, BCE Loss: 9.3298
Epoch 70, Loss: 8.9643, BCE Loss: 8.9643
Epoch 80, Loss: 8.8871, BCE Loss: 8.8871
Epoch 90, Loss: 8.5866, BCE Loss: 8.5866
Epoch 100, Loss: 8.5542, BCE Loss: 8.5542
Epoch 110, Loss: 8.5401, BCE Loss: 8.5401
Epoch 120, Loss: 8.5321, BCE Loss: 8.5321
Epoch 130, Loss: 8.5291, BCE Loss: 8.5291
Epoch 140, Loss: 8.5263, BCE Loss: 8.5263
Epoch 150, Loss: 8.5240, BCE Loss: 8.5240
Epoch 160, Loss: 8.5221, BCE Loss: 8.5221
Epoch 170, Loss: 8.5204, BCE Loss: 8.5204
Epoch 180, Loss: 8.5189, BCE Loss: 8.5189
Epoch 190, Loss: 8.5176, BCE Loss: 8.5176
Epoch 200, Loss: 8.5165, BCE Loss: 8.5165
Epoch 210, Loss: 8.5155, BCE Loss: 8.5155
Epoch 220, Loss: 8.5145, BCE Loss: 8.5145
Epoch 230, Loss: 8.5136, BCE Loss: 8.5136
Epoch 240, Loss: 8.5128, BCE Loss: 8.5128
Epoch 250, Loss: 8.5120, BCE Loss: 8.5120
Epoch 260, Loss: 8.5112, BCE Loss: 8.5112
Epoch 270, Loss: 8.5105, BCE Loss: 8.5105
Epoch 280, Loss: 8.5098, BCE Loss: 8.5098
Epoch 290, Loss: 8.5092, BCE Loss: 8.5092
Epoch 300, Loss: 8.5086, BCE Loss: 8.5086
Epoch 310, Loss: 8.5080, BCE Loss: 8.5080
Epoch 320, Loss: 8.5074, BCE Loss: 8.5074
Epoch 330, Loss: 8.5069, BCE Loss: 8.5069
Epoch 340, Loss: 8.5064, BCE Loss: 8.5064
Epoch 350, Loss: 8.5059, BCE Loss: 8.5059
Epoch 360, Loss: 8.5054, BCE Loss: 8.5054
Epoch 370, Loss: 8.5050, BCE Loss: 8.5050
Epoch 380, Loss: 8.5045, BCE Loss: 8.5045
Epoch 390, Loss: 8.5041, BCE Loss: 8.5041
Epoch 400, Loss: 8.5037, BCE Loss: 8.5037
Epoch 410, Loss: 8.5033, BCE Loss: 8.5033
Epoch 420, Loss: 8.5029, BCE Loss: 8.5029
Epoch 430, Loss: 8.5025, BCE Loss: 8.5025
Epoch 440, Loss: 8.5021, BCE Loss: 8.5021
Epoch 450, Loss: 8.5017, BCE Loss: 8.5017
Epoch 460, Loss: 8.5014, BCE Loss: 8.5014
Epoch 470, Loss: 8.5010, BCE Loss: 8.5010
Epoch 480, Loss: 8.5007, BCE Loss: 8.5007
Epoch 490, Loss: 8.5003, BCE Loss: 8.5003
2025-05-24 16:06:29,770 - INFO - Model saved to models/hetero_gnn_model.pth
Epoch 0, Loss: 3.0472707748413086, Accuracy: 11.88%
Epoch 10, Loss: 1.238675832748413, Accuracy: 61.25%
Epoch 20, Loss: 0.5268548727035522, Accuracy: 90.00%
Epoch 30, Loss: 0.14138653874397278, Accuracy: 99.38%
Epoch 40, Loss: 0.03327648341655731, Accuracy: 100.00%
Epoch 50, Loss: 0.010980690829455853, Accuracy: 100.00%
Epoch 60, Loss: 0.005352207459509373, Accuracy: 100.00%
Epoch 70, Loss: 0.0034587078262120485, Accuracy: 100.00%
Epoch 80, Loss: 0.0025906055234372616, Accuracy: 100.00%
Epoch 90, Loss: 0.0021139695309102535, Accuracy: 100.00%
Epoch 100, Loss: 0.0017967384774237871, Accuracy: 100.00%
Epoch 110, Loss: 0.0015619111945852637, Accuracy: 100.00%
Epoch 120, Loss: 0.001372488564811647, Accuracy: 100.00%
Epoch 130, Loss: 0.0012126945657655597, Accuracy: 100.00%
Epoch 140, Loss: 0.0010769485961645842, Accuracy: 100.00%
Epoch 150, Loss: 0.0009625733946450055, Accuracy: 100.00%
Epoch 160, Loss: 0.0008420699159614742, Accuracy: 100.00%
Epoch 170, Loss: 0.0007378100999630988, Accuracy: 100.00%
Epoch 180, Loss: 0.0006478129071183503, Accuracy: 100.00%
Epoch 190, Loss: 0.000574433128349483, Accuracy: 100.00%
2025-05-24 16:06:43,838 - INFO - Model saved to models/hetero_gnn_edge_regressor.pth
Epoch 0, Loss: 18.3913, BCE Loss: 18.3913
Epoch 10, Loss: 18.2850, BCE Loss: 18.2850
Epoch 20, Loss: 14.9381, BCE Loss: 14.9381
Epoch 30, Loss: 14.2361, BCE Loss: 14.2361
Epoch 40, Loss: 13.3838, BCE Loss: 13.3838
Epoch 50, Loss: 12.6140, BCE Loss: 12.6140
Epoch 60, Loss: 12.0341, BCE Loss: 12.0341
Epoch 70, Loss: 9.9141, BCE Loss: 9.9141
Epoch 80, Loss: 6.0896, BCE Loss: 6.0896
Epoch 90, Loss: 4.0342, BCE Loss: 4.0342
Epoch 100, Loss: 3.5104, BCE Loss: 3.5104
Epoch 110, Loss: 3.3846, BCE Loss: 3.3846
Epoch 120, Loss: 3.3227, BCE Loss: 3.3227
Epoch 130, Loss: 3.0373, BCE Loss: 3.0373
Epoch 140, Loss: 2.9782, BCE Loss: 2.9782
Epoch 150, Loss: 2.9735, BCE Loss: 2.9735
Epoch 160, Loss: 2.9725, BCE Loss: 2.9725
Epoch 170, Loss: 2.9722, BCE Loss: 2.9722
Epoch 180, Loss: 2.9727, BCE Loss: 2.9727
Epoch 190, Loss: 2.9728, BCE Loss: 2.9728
Epoch 200, Loss: 2.9728, BCE Loss: 2.9728
Epoch 210, Loss: 2.9729, BCE Loss: 2.9729
Epoch 220, Loss: 2.9727, BCE Loss: 2.9727
Epoch 230, Loss: 2.9729, BCE Loss: 2.9729
Epoch 240, Loss: 2.9732, BCE Loss: 2.9732
Epoch 250, Loss: 2.9733, BCE Loss: 2.9733
Epoch 260, Loss: 2.9735, BCE Loss: 2.9735
Epoch 270, Loss: 2.9737, BCE Loss: 2.9737
Epoch 280, Loss: 2.9739, BCE Loss: 2.9739
Epoch 290, Loss: 2.9740, BCE Loss: 2.9740
Epoch 300, Loss: 2.9742, BCE Loss: 2.9742
Epoch 310, Loss: 2.9743, BCE Loss: 2.9743
Epoch 320, Loss: 2.9745, BCE Loss: 2.9745
Epoch 330, Loss: 2.9746, BCE Loss: 2.9746
Epoch 340, Loss: 2.9747, BCE Loss: 2.9747
Epoch 350, Loss: 2.9749, BCE Loss: 2.9749
Epoch 360, Loss: 2.9750, BCE Loss: 2.9750
Epoch 370, Loss: 2.9751, BCE Loss: 2.9751
Epoch 380, Loss: 2.9753, BCE Loss: 2.9753
Epoch 390, Loss: 2.9754, BCE Loss: 2.9754
Epoch 400, Loss: 2.9755, BCE Loss: 2.9755
Epoch 410, Loss: 2.9757, BCE Loss: 2.9757
Epoch 420, Loss: 2.3602, BCE Loss: 2.3602
Epoch 430, Loss: 2.3554, BCE Loss: 2.3554
Epoch 440, Loss: 2.3530, BCE Loss: 2.3530
Epoch 450, Loss: 2.3548, BCE Loss: 2.3548
Epoch 460, Loss: 2.3543, BCE Loss: 2.3543
Epoch 470, Loss: 2.3530, BCE Loss: 2.3530
Epoch 480, Loss: 2.3526, BCE Loss: 2.3526
Epoch 490, Loss: 2.3521, BCE Loss: 2.3521
2025-05-24 16:07:51,202 - INFO - Model saved to models/hetero_gnn_model.pth
Epoch 0, Loss: 3.6518051624298096, Accuracy: 12.50%
Epoch 10, Loss: 1.7093578577041626, Accuracy: 44.38%
Epoch 20, Loss: 0.9138310551643372, Accuracy: 80.00%
Epoch 30, Loss: 0.4499664902687073, Accuracy: 98.12%
Epoch 40, Loss: 0.2560918927192688, Accuracy: 99.38%
Epoch 50, Loss: 0.19054047763347626, Accuracy: 100.00%
Epoch 60, Loss: 0.16909097135066986, Accuracy: 100.00%
Epoch 70, Loss: 0.16073773801326752, Accuracy: 100.00%
Epoch 80, Loss: 0.15670102834701538, Accuracy: 100.00%
Epoch 90, Loss: 0.15433228015899658, Accuracy: 100.00%
Epoch 100, Loss: 0.15268254280090332, Accuracy: 100.00%
Epoch 110, Loss: 0.15136857330799103, Accuracy: 100.00%
Epoch 120, Loss: 0.1502021849155426, Accuracy: 100.00%
Epoch 130, Loss: 0.14917834103107452, Accuracy: 100.00%
Epoch 140, Loss: 0.14835648238658905, Accuracy: 100.00%
Epoch 150, Loss: 0.14768032729625702, Accuracy: 100.00%
Epoch 160, Loss: 0.1471225470304489, Accuracy: 100.00%
Epoch 170, Loss: 0.14664803445339203, Accuracy: 100.00%
Epoch 180, Loss: 0.14625480771064758, Accuracy: 100.00%
Epoch 190, Loss: 0.14591296017169952, Accuracy: 100.00%
2025-05-24 16:08:04,541 - INFO - Model saved to models/hetero_gnn_edge_regressor.pth
Epoch 0, Loss: 14.6430, BCE Loss: 14.4802
Epoch 10, Loss: 11.3975, BCE Loss: 11.2360
Epoch 20, Loss: 9.7308, BCE Loss: 9.5699
Epoch 30, Loss: 9.0932, BCE Loss: 8.9333
Epoch 40, Loss: 8.2953, BCE Loss: 8.1365
Epoch 50, Loss: 7.6311, BCE Loss: 7.4734
Epoch 60, Loss: 7.2788, BCE Loss: 7.1221
Epoch 70, Loss: 6.9523, BCE Loss: 6.7966
Epoch 80, Loss: 6.9208, BCE Loss: 6.7661
Epoch 90, Loss: 6.9225, BCE Loss: 6.7688
Epoch 100, Loss: 6.9152, BCE Loss: 6.7624
Epoch 110, Loss: 6.9106, BCE Loss: 6.7587
Epoch 120, Loss: 6.9105, BCE Loss: 6.7594
Epoch 130, Loss: 6.9112, BCE Loss: 6.7607
Epoch 140, Loss: 6.6371, BCE Loss: 6.4872
Epoch 150, Loss: 6.0367, BCE Loss: 5.8874
Epoch 160, Loss: 5.4085, BCE Loss: 5.2596
Epoch 170, Loss: 5.3794, BCE Loss: 5.2307
Epoch 180, Loss: 5.3573, BCE Loss: 5.2089
Epoch 190, Loss: 5.0483, BCE Loss: 4.9003
Epoch 200, Loss: 5.0462, BCE Loss: 4.8987
Epoch 210, Loss: 5.0426, BCE Loss: 4.8955
Epoch 220, Loss: 5.0455, BCE Loss: 4.8987
Epoch 230, Loss: 5.0482, BCE Loss: 4.9017
Epoch 240, Loss: 5.0461, BCE Loss: 4.8999
Epoch 250, Loss: 5.0441, BCE Loss: 4.8982
Epoch 260, Loss: 5.0428, BCE Loss: 4.8972
Epoch 270, Loss: 5.0422, BCE Loss: 4.8968
Epoch 280, Loss: 5.0417, BCE Loss: 4.8967
Epoch 290, Loss: 5.0411, BCE Loss: 4.8963
Epoch 300, Loss: 5.0407, BCE Loss: 4.8962
Epoch 310, Loss: 5.0403, BCE Loss: 4.8960
Epoch 320, Loss: 5.0400, BCE Loss: 4.8959
Epoch 330, Loss: 5.0397, BCE Loss: 4.8959
Epoch 340, Loss: 5.0395, BCE Loss: 4.8960
Epoch 350, Loss: 5.0393, BCE Loss: 4.8960
Epoch 360, Loss: 5.0392, BCE Loss: 4.8961
Epoch 370, Loss: 5.0391, BCE Loss: 4.8962
Epoch 380, Loss: 5.0390, BCE Loss: 4.8963
Epoch 390, Loss: 5.0390, BCE Loss: 4.8965
Epoch 400, Loss: 5.0390, BCE Loss: 4.8966
Epoch 410, Loss: 5.0390, BCE Loss: 4.8968
Epoch 420, Loss: 5.0390, BCE Loss: 4.8970
Epoch 430, Loss: 5.0390, BCE Loss: 4.8972
Epoch 440, Loss: 5.0390, BCE Loss: 4.8974
Epoch 450, Loss: 5.0391, BCE Loss: 4.8976
Epoch 460, Loss: 5.0392, BCE Loss: 4.8978
Epoch 470, Loss: 5.0393, BCE Loss: 4.8981
Epoch 480, Loss: 5.0393, BCE Loss: 4.8983
Epoch 490, Loss: 5.0394, BCE Loss: 4.8985
